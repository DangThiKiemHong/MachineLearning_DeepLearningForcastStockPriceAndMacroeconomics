{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_AmfjEH808l"
   },
   "source": [
    "**Hồi Quy Logistic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9yaEBAQ86Uy"
   },
   "source": [
    "1. Tải dữ liệu\n",
    "2. Tạo biến Y=0 nếu giá CK giảm và biến Y=1 nếu giá CK tăng.\n",
    "3. Sử dụng hàm LogisticRegression từ thư viện sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6AW3-ig7dST"
   },
   "source": [
    "**VCB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1726725598229,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "9EDAg8C-7wEE",
    "outputId": "00ffb391-ab75-448b-ced7-e0a9b7e18134"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>14.03</td>\n",
       "      <td>14.21</td>\n",
       "      <td>13.90</td>\n",
       "      <td>14.12</td>\n",
       "      <td>310010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>14.12</td>\n",
       "      <td>15.05</td>\n",
       "      <td>14.12</td>\n",
       "      <td>15.05</td>\n",
       "      <td>1684600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>15.09</td>\n",
       "      <td>15.31</td>\n",
       "      <td>14.65</td>\n",
       "      <td>14.87</td>\n",
       "      <td>1430340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>14.92</td>\n",
       "      <td>15.49</td>\n",
       "      <td>14.87</td>\n",
       "      <td>15.31</td>\n",
       "      <td>904240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>15.45</td>\n",
       "      <td>16.38</td>\n",
       "      <td>15.45</td>\n",
       "      <td>16.33</td>\n",
       "      <td>2286680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        time   open   high    low  close   volume\n",
       "0           0  2015-01-05  14.03  14.21  13.90  14.12   310010\n",
       "1           1  2015-01-06  14.12  15.05  14.12  15.05  1684600\n",
       "2           2  2015-01-07  15.09  15.31  14.65  14.87  1430340\n",
       "3           3  2015-01-08  14.92  15.49  14.87  15.31   904240\n",
       "4           4  2015-01-09  15.45  16.38  15.45  16.33  2286680"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Đọc dữ liệu từ file CSV (có thể thay bằng file của bạn)\n",
    "#df = pd.read_csv('VCB_hose.csv')\n",
    "file_path = r'D:\\DeTaiNam2024\\SolieuHong\\VCB.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "# Kiểm tra tiêu đề các cột\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1726725602013,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "vBEVaiUMTo2F",
    "outputId": "ed238e0b-c49a-4d22-aad5-3529a306ab3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            time  close  Y\n",
      "0     2015-01-05  14.12  0\n",
      "1     2015-01-06  15.05  1\n",
      "2     2015-01-07  14.87  0\n",
      "3     2015-01-08  15.31  1\n",
      "4     2015-01-09  16.33  1\n",
      "...          ...    ... ..\n",
      "2421  2024-09-13  89.90  1\n",
      "2422  2024-09-16  88.90  0\n",
      "2423  2024-09-17  90.50  1\n",
      "2424  2024-09-18  91.00  1\n",
      "2425  2024-09-19  91.60  1\n",
      "\n",
      "[2426 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sắp xếp theo ngày\n",
    "df = df.sort_values('time')\n",
    "\n",
    "# Tạo cột Y: nếu giá đóng cửa hôm nay thấp hơn hôm qua, Y=0, nếu ngược lại Y=1\n",
    "df['Y'] = (df['close'].diff() > 0).astype(int)\n",
    "\n",
    "# Hiển thị dữ liệu với cột Y\n",
    "print(df[['time', 'close', 'Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1726725605666,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "DccV_4H6LmpO",
    "outputId": "c6af5f19-1182-4fa0-bdeb-81f013d00853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       265\n",
      "           1       0.00      0.00      0.00       220\n",
      "\n",
      "    accuracy                           0.55       485\n",
      "   macro avg       0.27      0.50      0.35       485\n",
      "weighted avg       0.30      0.55      0.39       485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Tạo các đặc trưng (ở đây ta chỉ sử dụng giá hôm trước và khối lượng giao dịch)\n",
    "# Shift dữ liệu Close để lấy giá của ngày trước làm đặc trưng\n",
    "df['Close_lag1'] = df['close'].shift(1)\n",
    "df['Volume_lag1'] = df['volume'].shift(1)\n",
    "\n",
    "# Loại bỏ các hàng chứa giá trị NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn các đặc trưng (X) và mục tiêu (Y)\n",
    "X = df[['Close_lag1', 'Volume_lag1']]\n",
    "Y = df['Y']\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình hồi quy logistic\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Báo cáo chi tiết kết quả dự đoán\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 505,
     "status": "ok",
     "timestamp": 1726724987396,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "7bn5zNks9voV",
    "outputId": "a470f614-b649-48dc-95ec-212a88134969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           time   close  Y\n",
      "276   1/10/2018  214.26  0\n",
      "525   1/10/2019  192.42  0\n",
      "777   1/10/2020  251.11  1\n",
      "1027  1/10/2021  570.49  1\n",
      "48    1/11/2017  193.87  0\n",
      "...         ...     ... ..\n",
      "1490   9/8/2023  492.69  0\n",
      "509    9/9/2019  183.42  0\n",
      "761    9/9/2020  232.80  1\n",
      "1011   9/9/2021  589.51  1\n",
      "1261   9/9/2022  511.66  0\n",
      "\n",
      "[1706 rows x 3 columns]\n",
      "Accuracy: 0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65       163\n",
      "           1       0.00      0.00      0.00       178\n",
      "\n",
      "    accuracy                           0.48       341\n",
      "   macro avg       0.24      0.50      0.32       341\n",
      "weighted avg       0.23      0.48      0.31       341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Đọc dữ liệu từ file CSV (có thể thay bằng file của bạn)\n",
    "file_path = r'D:\\DeTaiNam2024\\SolieuHong\\HNX.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "# Kiểm tra tiêu đề các cột\n",
    "df.head()\n",
    "# Sắp xếp theo ngày\n",
    "df = df.sort_values('time')\n",
    "\n",
    "# Tạo cột Y: nếu giá đóng cửa hôm nay thấp hơn hôm qua, Y=0, nếu ngược lại Y=1\n",
    "df['Y'] = (df['close'].diff() > 0).astype(int)\n",
    "\n",
    "# Hiển thị dữ liệu với cột Y\n",
    "print(df[['time', 'close', 'Y']])\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Tạo các đặc trưng (ở đây ta chỉ sử dụng giá hôm trước và khối lượng giao dịch)\n",
    "# Shift dữ liệu Close để lấy giá của ngày trước làm đặc trưng\n",
    "df['Close_lag1'] = df['close'].shift(1)\n",
    "df['Volume_lag1'] = df['volume'].shift(1)\n",
    "\n",
    "# Loại bỏ các hàng chứa giá trị NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn các đặc trưng (X) và mục tiêu (Y)\n",
    "X = df[['Close_lag1', 'Volume_lag1']]\n",
    "Y = df['Y']\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình hồi quy logistic\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Báo cáo chi tiết kết quả dự đoán\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFCwNgS1xcWL"
   },
   "source": [
    "**Hồi quy Logistic sử dụng Thuật toán  Batch Gradient Descent cho Hồi quy Logistic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1726725712442,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "WvlylXmZxjXA",
    "outputId": "41c3088f-b723-4691-e199-f7818c0728e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6931471805599453\n",
      "Iteration 100, Loss: 0.6923686195584698\n",
      "Iteration 200, Loss: 0.6918986028521242\n",
      "Iteration 300, Loss: 0.691614746717364\n",
      "Iteration 400, Loss: 0.6914432412605611\n",
      "Iteration 500, Loss: 0.691339571939769\n",
      "Iteration 600, Loss: 0.6912768819299622\n",
      "Iteration 700, Loss: 0.6912389591714884\n",
      "Iteration 800, Loss: 0.6912160118387798\n",
      "Iteration 900, Loss: 0.6912021227345617\n",
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       265\n",
      "           1       0.67      0.02      0.04       220\n",
      "\n",
      "    accuracy                           0.55       485\n",
      "   macro avg       0.61      0.51      0.37       485\n",
      "weighted avg       0.60      0.55      0.40       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Hàm sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Hàm mất mát (binary cross-entropy)\n",
    "def compute_loss(Y, Y_hat):\n",
    "    m = Y.shape[0]\n",
    "    return -(1/m) * np.sum(Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat))\n",
    "\n",
    "# Hàm Batch Gradient Descent\n",
    "def batch_gradient_descent(X, Y, learning_rate=0.01, iterations=1000):\n",
    "    m, n = X.shape\n",
    "    # Khởi tạo tham số (weights và bias)\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Tính toán dự đoán Y_hat\n",
    "        Z = np.dot(X, weights) + bias\n",
    "        Y_hat = sigmoid(Z)\n",
    "\n",
    "        # Tính gradient của hàm mất mát\n",
    "        dw = (1/m) * np.dot(X.T, (Y_hat - Y))\n",
    "        db = (1/m) * np.sum(Y_hat - Y)\n",
    "\n",
    "        # Cập nhật trọng số\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "\n",
    "        # Tính và lưu lại hàm mất mát\n",
    "        loss = compute_loss(Y, Y_hat)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # In ra mỗi 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration {i}, Loss: {loss}')\n",
    "\n",
    "    return weights, bias, losses\n",
    "\n",
    "# Hàm dự đoán\n",
    "def predict(X, weights, bias):\n",
    "    Z = np.dot(X, weights) + bias\n",
    "    Y_hat = sigmoid(Z)\n",
    "    return np.where(Y_hat >= 0.5, 1, 0)\n",
    "\n",
    "# Đọc dữ liệu\n",
    "file_path = r'D:\\DeTaiNam2024\\SolieuHong\\VCB.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Giả sử dữ liệu có cột: 'time', 'close', 'Volume'\n",
    "df = df.sort_values('time')\n",
    "\n",
    "# Tạo biến Y: 1 nếu giá tăng, 0 nếu giá giảm\n",
    "df['Y'] = (df['close'].diff() > 0).astype(int)\n",
    "\n",
    "# Tạo các đặc trưng (ở đây chỉ sử dụng giá hôm trước và khối lượng giao dịch)\n",
    "df['Close_lag1'] = df['close'].shift(1)\n",
    "df['Volume_lag1'] = df['volume'].shift(1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn X (các đặc trưng) và Y (nhãn mục tiêu)\n",
    "X = df[['Close_lag1', 'Volume_lag1']].values\n",
    "Y = df['Y'].values\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình bằng Batch Gradient Descent\n",
    "weights, bias, losses = batch_gradient_descent(X_train, Y_train, learning_rate=0.01, iterations=1000)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "Y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = np.mean(Y_pred == Y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "# Báo cáo chi tiết kết quả dự đoán\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRyYYJ_PyQVl"
   },
   "source": [
    "**Hồi quy Logistic sử dụng Thuật toán Stochastic Gradient Descent cho Hồi quy Logistic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76736,
     "status": "ok",
     "timestamp": 1726726759787,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "W0o7xYkiyaLF",
    "outputId": "ebedfd0d-5d95-4112-e343-0987c2dbfe6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6931416153996103\n",
      "Iteration 100, Loss: 0.6923527462556451\n",
      "Iteration 200, Loss: 0.6918893571367302\n",
      "Iteration 300, Loss: 0.6915759936068767\n",
      "Iteration 400, Loss: 0.6914142051262017\n",
      "Iteration 500, Loss: 0.691317409333731\n",
      "Iteration 600, Loss: 0.6912742789286171\n",
      "Iteration 700, Loss: 0.6912410359619138\n",
      "Iteration 800, Loss: 0.6912209202604241\n",
      "Iteration 900, Loss: 0.6912100246202729\n",
      "Accuracy: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.71       265\n",
      "           1       0.67      0.02      0.04       220\n",
      "\n",
      "    accuracy                           0.55       485\n",
      "   macro avg       0.61      0.51      0.37       485\n",
      "weighted avg       0.60      0.55      0.40       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Hàm sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Hàm mất mát (binary cross-entropy)\n",
    "def compute_loss(Y, Y_hat):\n",
    "    m = Y.shape[0]\n",
    "    return -(1/m) * np.sum(Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat))\n",
    "\n",
    "# Hàm Stochastic Gradient Descent\n",
    "def stochastic_gradient_descent(X, Y, learning_rate=0.01, iterations=1000):\n",
    "    m, n = X.shape\n",
    "    # Khởi tạo tham số (weights và bias)\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        for j in range(m):  # Cập nhật cho từng mẫu dữ liệu\n",
    "            # Chọn một mẫu ngẫu nhiên\n",
    "            random_index = np.random.randint(m)\n",
    "            X_sample = X[random_index].reshape(1, -1)\n",
    "            Y_sample = Y[random_index].reshape(1, -1)\n",
    "\n",
    "            # Tính toán dự đoán Y_hat cho mẫu này\n",
    "            Z = np.dot(X_sample, weights) + bias\n",
    "            Y_hat = sigmoid(Z)\n",
    "\n",
    "            # Tính gradient cho mẫu này\n",
    "            dw = np.dot(X_sample.T, (Y_hat - Y_sample)) / m\n",
    "            db = (Y_hat - Y_sample) / m\n",
    "\n",
    "            # Cập nhật trọng số\n",
    "            weights -= learning_rate * dw.ravel()\n",
    "            bias -= learning_rate * db.ravel()\n",
    "\n",
    "        # Tính toán hàm mất mát sau mỗi lần lặp trên tất cả các mẫu\n",
    "        Z_all = np.dot(X, weights) + bias\n",
    "        Y_hat_all = sigmoid(Z_all)\n",
    "        loss = compute_loss(Y, Y_hat_all)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # In ra mỗi 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration {i}, Loss: {loss}')\n",
    "\n",
    "    return weights, bias, losses\n",
    "\n",
    "# Hàm dự đoán\n",
    "def predict(X, weights, bias):\n",
    "    Z = np.dot(X, weights) + bias\n",
    "    Y_hat = sigmoid(Z)\n",
    "    return np.where(Y_hat >= 0.5, 1, 0)\n",
    "\n",
    "# Đọc dữ liệu\n",
    "file_path = r'D:\\DeTaiNam2024\\SolieuHong\\VCB.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Giả sử dữ liệu có cột: 'time', 'close', 'volume'\n",
    "df = df.sort_values('time')\n",
    "\n",
    "# Tạo biến Y: 1 nếu giá tăng, 0 nếu giá giảm\n",
    "df['Y'] = (df['close'].diff() > 0).astype(int)\n",
    "\n",
    "# Tạo các đặc trưng (ở đây chỉ sử dụng giá hôm trước và khối lượng giao dịch)\n",
    "df['Close_lag1'] = df['close'].shift(1)\n",
    "df['Volume_lag1'] = df['volume'].shift(1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn X (các đặc trưng) và Y (nhãn mục tiêu)\n",
    "X = df[['Close_lag1', 'Volume_lag1']].values\n",
    "Y = df['Y'].values\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình bằng Stochastic Gradient Descent\n",
    "weights, bias, losses = stochastic_gradient_descent(X_train, Y_train, learning_rate=0.01, iterations=1000)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "Y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = np.mean(Y_pred == Y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "# Báo cáo chi tiết kết quả dự đoán\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5587628865979382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70       265\n",
      "           1       0.59      0.09      0.15       220\n",
      "\n",
      "    accuracy                           0.56       485\n",
      "   macro avg       0.58      0.52      0.43       485\n",
      "weighted avg       0.57      0.56      0.45       485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dựa trên thư viện SGDClassifier trong Sklearnt \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Đọc dữ liệu\n",
    "file_path = r'D:\\DeTaiNam2024\\SolieuHong\\VCB.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Giả sử dữ liệu có cột: 'time', 'close', 'volume'\n",
    "df = df.sort_values('time')\n",
    "\n",
    "# Tạo biến Y: 1 nếu giá tăng, 0 nếu giá giảm\n",
    "df['Y'] = (df['close'].diff() > 0).astype(int)\n",
    "\n",
    "# Tạo các đặc trưng (ở đây chỉ sử dụng giá hôm trước và khối lượng giao dịch)\n",
    "df['Close_lag1'] = df['close'].shift(1)\n",
    "df['Volume_lag1'] = df['volume'].shift(1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn X (các đặc trưng) và Y (nhãn mục tiêu)\n",
    "X = df[['Close_lag1', 'Volume_lag1']].values\n",
    "Y = df['Y'].values\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "# Khởi tạo mô hình SGD Logistic Regression\n",
    "sgd_classifier = SGDClassifier(loss='epsilon_insensitive', learning_rate='optimal', eta0=0.01, max_iter=1000)\n",
    "# Huấn luyện mô hình\n",
    "sgd_classifier.fit(X_train, Y_train)\n",
    "# Dự đoán\n",
    "Y_pred = sgd_classifier.predict(X_test)\n",
    "# Đánh giá\n",
    "accuracy = sgd_classifier.score(X_test, Y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "# Báo cáo chi tiết kết quả dự đoán\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIc0a+yfSUdkpi0jU24TaG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
