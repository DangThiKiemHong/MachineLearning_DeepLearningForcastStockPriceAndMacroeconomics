{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_AmfjEH808l"
   },
   "source": [
    "**Hồi Quy Logistic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9yaEBAQ86Uy"
   },
   "source": [
    "1. Tải dữ liệu\n",
    "2. Tạo biến Y=0 nếu chỉ số  giảm và biến Y=1 nếu chỉ số tăng.\n",
    "3. Sử dụng hàm LogisticRegression từ thư viện sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71cN2d-2lPFS"
   },
   "source": [
    "**CHỈ SỐ KINH TẾ VĨ MÔ: CPI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1438,
     "status": "ok",
     "timestamp": 1726739240776,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "rlVUODkMlV0x",
    "outputId": "58930840-6084-4fdc-da54-8fd56c51a057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác của mô hình: 67.69%\n",
      "Confusion Matrix:\n",
      "[[18 14]\n",
      " [ 7 26]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.56      0.63        32\n",
      "           1       0.65      0.79      0.71        33\n",
      "\n",
      "    accuracy                           0.68        65\n",
      "   macro avg       0.69      0.68      0.67        65\n",
      "weighted avg       0.68      0.68      0.67        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Bước 1: Đọc dữ liệu, tạo biến mục tiêu Y\n",
    "data = pd.read_csv('cpi.csv')\n",
    "#Kiểm tra tiêu đề các cột\n",
    "df.head()\n",
    "#Dữ liệu có cột: 't', 'cpi'\n",
    "df = df.sort_values('t')\n",
    "\n",
    "# Tạo biến Y: 1 nếu giá tăng, 0 nếu giá giảm\n",
    "df['Y'] = (df['cpi'].diff() > 0).astype(int)\n",
    "\n",
    "# Bước 2: Tạo các đặc trưng (ở đây chỉ sử dụng cpi hôm trước)\n",
    "df['cpi_lag1'] = df['cpi'].shift(1)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn X (các đặc trưng) và Y (nhãn mục tiêu)\n",
    "X = df[['cpi_lag1']].values\n",
    "Y = df['Y'].values\n",
    "# Bước 3: Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bước 4: Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Bước 5: Huấn luyện mô hình Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Bước 6: Dự đoán trên tập kiểm tra\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Bước 7: Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Độ chính xác của mô hình: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13093,
     "status": "ok",
     "timestamp": 1726739495344,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "NWfRrMLlsPya",
    "outputId": "34d870e1-37d6-4978-af04-e1cc699bad24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6927907906371544\n",
      "Iteration 100, Loss: 0.6588742199447375\n",
      "Iteration 200, Loss: 0.6372632019459956\n",
      "Iteration 300, Loss: 0.6236162433579624\n",
      "Iteration 400, Loss: 0.6147627716877456\n",
      "Iteration 500, Loss: 0.6086645195483775\n",
      "Iteration 600, Loss: 0.6040219110786471\n",
      "Iteration 700, Loss: 0.6006502038139464\n",
      "Iteration 800, Loss: 0.5982574947432919\n",
      "Iteration 900, Loss: 0.5964305297860713\n",
      "Accuracy: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.58      0.65        31\n",
      "           1       0.68      0.82      0.75        34\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.72      0.70      0.70        65\n",
      "weighted avg       0.71      0.71      0.70        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Hàm sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Hàm mất mát (binary cross-entropy)\n",
    "def compute_loss(Y, Y_hat):\n",
    "    m = Y.shape[0]\n",
    "    return -(1/m) * np.sum(Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat))\n",
    "\n",
    "# Hàm Stochastic Gradient Descent\n",
    "def stochastic_gradient_descent(X, Y, learning_rate=0.01, iterations=1000):\n",
    "    m, n = X.shape\n",
    "    # Khởi tạo tham số (weights và bias)\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        for j in range(m):  # Cập nhật cho từng mẫu dữ liệu\n",
    "            # Chọn một mẫu ngẫu nhiên\n",
    "            random_index = np.random.randint(m)\n",
    "            X_sample = X[random_index].reshape(1, -1)\n",
    "            Y_sample = Y[random_index].reshape(1, -1)\n",
    "\n",
    "            # Tính toán dự đoán Y_hat cho mẫu này\n",
    "            Z = np.dot(X_sample, weights) + bias\n",
    "            Y_hat = sigmoid(Z)\n",
    "\n",
    "            # Tính gradient cho mẫu này\n",
    "            dw = np.dot(X_sample.T, (Y_hat - Y_sample)) / m\n",
    "            db = (Y_hat - Y_sample) / m\n",
    "\n",
    "            # Cập nhật trọng số\n",
    "            weights -= learning_rate * dw.ravel()\n",
    "            bias -= learning_rate * db.ravel()\n",
    "\n",
    "        # Tính toán hàm mất mát sau mỗi lần lặp trên tất cả các mẫu\n",
    "        Z_all = np.dot(X, weights) + bias\n",
    "        Y_hat_all = sigmoid(Z_all)\n",
    "        loss = compute_loss(Y, Y_hat_all)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # In ra mỗi 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration {i}, Loss: {loss}')\n",
    "\n",
    "    return weights, bias, losses\n",
    "\n",
    "# Hàm dự đoán\n",
    "def predict(X, weights, bias):\n",
    "    Z = np.dot(X, weights) + bias\n",
    "    Y_hat = sigmoid(Z)\n",
    "    return np.where(Y_hat >= 0.5, 1, 0)\n",
    "\n",
    "# Bước 1: Đọc dữ liệu, tạo biến mục tiêu Y\n",
    "data = pd.read_csv('cpi.csv')\n",
    "#Kiểm tra tiêu đề các cột\n",
    "df.head()\n",
    "#Dữ liệu có cột: 't', 'cpi'\n",
    "df = df.sort_values('t')\n",
    "\n",
    "# Tạo biến Y: 1 nếu giá tăng, 0 nếu giá giảm\n",
    "df['Y'] = (df['cpi'].diff() > 0).astype(int)\n",
    "\n",
    "# Bước 2: Tạo các đặc trưng (ở đây chỉ sử dụng cpi hôm trước)\n",
    "df['cpi_lag1'] = df['cpi'].shift(1)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn X (các đặc trưng) và Y (nhãn mục tiêu)\n",
    "X = df[['cpi_lag1']].values\n",
    "Y = df['Y'].values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình bằng Stochastic Gradient Descent\n",
    "weights, bias, losses = stochastic_gradient_descent(X_train, Y_train, learning_rate=0.01, iterations=1000)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "Y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = np.mean(Y_pred == Y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "# Báo cáo chi tiết kết quả dự đoán\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1726739809927,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "zTqhNniEtcrE",
    "outputId": "f57ce911-3eff-47f7-ce17-d5950f98764c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 0.6931471805599453\n",
      "Iteration 100, Loss: 0.6604527084833003\n",
      "Iteration 200, Loss: 0.639916716416077\n",
      "Iteration 300, Loss: 0.6266248257841454\n",
      "Iteration 400, Loss: 0.6177417376882857\n",
      "Iteration 500, Loss: 0.6116315221020682\n",
      "Iteration 600, Loss: 0.6073235178961773\n",
      "Iteration 700, Loss: 0.6042219677986207\n",
      "Iteration 800, Loss: 0.6019491253566417\n",
      "Iteration 900, Loss: 0.6002583452080458\n",
      "Accuracy: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.54      0.63        35\n",
      "           1       0.60      0.80      0.69        30\n",
      "\n",
      "    accuracy                           0.66        65\n",
      "   macro avg       0.68      0.67      0.66        65\n",
      "weighted avg       0.69      0.66      0.66        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Hàm sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Hàm mất mát (binary cross-entropy)\n",
    "def compute_loss(Y, Y_hat):\n",
    "    m = Y.shape[0]\n",
    "    return -(1/m) * np.sum(Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat))\n",
    "\n",
    "# Hàm Batch Gradient Descent\n",
    "def batch_gradient_descent(X, Y, learning_rate=0.01, iterations=1000):\n",
    "    m, n = X.shape\n",
    "    # Khởi tạo tham số (weights và bias)\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Tính toán dự đoán Y_hat\n",
    "        Z = np.dot(X, weights) + bias\n",
    "        Y_hat = sigmoid(Z)\n",
    "\n",
    "        # Tính gradient của hàm mất mát\n",
    "        dw = (1/m) * np.dot(X.T, (Y_hat - Y))\n",
    "        db = (1/m) * np.sum(Y_hat - Y)\n",
    "\n",
    "        # Cập nhật trọng số\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "\n",
    "        # Tính và lưu lại hàm mất mát\n",
    "        loss = compute_loss(Y, Y_hat)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # In ra mỗi 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration {i}, Loss: {loss}')\n",
    "\n",
    "    return weights, bias, losses\n",
    "\n",
    "# Hàm dự đoán\n",
    "def predict(X, weights, bias):\n",
    "    Z = np.dot(X, weights) + bias\n",
    "    Y_hat = sigmoid(Z)\n",
    "    return np.where(Y_hat >= 0.5, 1, 0)\n",
    "\n",
    "# Bước 1: Đọc dữ liệu, tạo biến mục tiêu Y\n",
    "data = pd.read_csv('cpi.csv')\n",
    "#Kiểm tra tiêu đề các cột\n",
    "df.head()\n",
    "#Dữ liệu có cột: 't', 'cpi'\n",
    "df = df.sort_values('t')\n",
    "\n",
    "# Tạo biến Y: 1 nếu giá tăng, 0 nếu giá giảm\n",
    "df['Y'] = (df['cpi'].diff() > 0).astype(int)\n",
    "\n",
    "# Bước 2: Tạo các đặc trưng (ở đây chỉ sử dụng cpi hôm trước)\n",
    "df['cpi_lag1'] = df['cpi'].shift(1)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Chọn X (các đặc trưng) và Y (nhãn mục tiêu)\n",
    "X = df[['cpi_lag1']].values\n",
    "Y = df['Y'].values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình bằng Batch Gradient Descent\n",
    "weights, bias, losses = batch_gradient_descent(X_train, Y_train, learning_rate=0.01, iterations=1000)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "Y_pred = predict(X_test, weights, bias)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = np.mean(Y_pred == Y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "# Báo cáo chi tiết kết quả dự đoán\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPIc0a+yfSUdkpi0jU24TaG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
