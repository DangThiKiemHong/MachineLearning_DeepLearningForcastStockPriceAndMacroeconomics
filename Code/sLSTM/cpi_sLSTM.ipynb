{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XLYnJKBXgm2k"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eHSj6Kgwg2HQ"
   },
   "outputs": [],
   "source": [
    "def plot_series(x, y, format=\"-\", start=0, end=None,\n",
    "                title=None, xlabel=None, ylabel=None, legend=None ):\n",
    "    \"\"\"\n",
    "    Visualizes time series data\n",
    "\n",
    "    Args:\n",
    "      x (array of int) - contains values for the x-axis\n",
    "      y (array of int or tuple of arrays) - contains the values for the y-axis\n",
    "      format (string) - line style when plotting the graph\n",
    "      label (string) - tag for the line\n",
    "      start (int) - first time step to plot\n",
    "      end (int) - last time step to plot\n",
    "      title (string) - title of the plot\n",
    "      xlabel (string) - label for the x-axis\n",
    "      ylabel (string) - label for the y-axis\n",
    "      legend (list of strings) - legend for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dimensions of the graph figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Check if there are more than two series to plot\n",
    "    if type(y) is tuple:\n",
    "\n",
    "      # Loop over the y elements\n",
    "      for y_curr in y:\n",
    "\n",
    "        # Plot the x and current y values\n",
    "        plt.plot(x[start:end], y_curr[start:end], format)\n",
    "\n",
    "    else:\n",
    "      # Plot the x and y values\n",
    "      plt.plot(x[start:end], y[start:end], format)\n",
    "\n",
    "    # Label the x-axis\n",
    "    plt.xlabel(xlabel)\n",
    "\n",
    "    # Label the y-axis\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    # Set the legend\n",
    "    if legend:\n",
    "      plt.legend(legend)\n",
    "\n",
    "    # Set the title\n",
    "    plt.title(title)\n",
    "\n",
    "    # Overlay a grid on the graph\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Draw the graph on screen\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "to0XzETfg3dU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VhrV4FMlg9F4"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('D:\\DeTaiNam2024\\SoLieu\\KinhTeViMo\\cpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1727056718664,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "OkJpIU_2g_bp",
    "outputId": "138da7c5-9c58-44d7-f353-4e279a359dc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tg</th>\n",
       "      <th>t</th>\n",
       "      <th>cpi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jan-95</td>\n",
       "      <td>103.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Feb-95</td>\n",
       "      <td>103.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mar-95</td>\n",
       "      <td>100.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Apr-95</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>May-95</td>\n",
       "      <td>101.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tg       t    cpi\n",
       "0   0  Jan-95  103.8\n",
       "1   1  Feb-95  103.4\n",
       "2   2  Mar-95  100.2\n",
       "3   3  Apr-95  101.0\n",
       "4   4  May-95  101.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 11451,
     "status": "ok",
     "timestamp": 1727056764571,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "1QzTd_9shFVB",
    "outputId": "8560f0ea-ca79-4aff-9b64-e4de39e8eb03"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Jan-95'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8992\\1808681669.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[1;31m# Append row and sunspot number to lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtime_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mclose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Jan-95'"
     ]
    }
   ],
   "source": [
    "# Initialize lists\n",
    "time_step = []\n",
    "close = []\n",
    "\n",
    "# Open CSV file\n",
    "with open('D:\\DeTaiNam2024\\SoLieu\\KinhTeViMo\\cpi.csv') as csvfile:\n",
    "\n",
    "  # Initialize reader\n",
    "  reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "  # Skip the first line\n",
    "  next(reader)\n",
    "\n",
    "  # Append row and sunspot number to lists\n",
    "  for row in reader:\n",
    "    time_step.append(int(row[1]))\n",
    "    close.append(float(row[2]))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "time = np.array(time_step)\n",
    "series = np.array(close)\n",
    "\n",
    "# Preview the data\n",
    "plot_series(time, series, xlabel='Năm', ylabel='CPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1gw92rUchQzw"
   },
   "outputs": [],
   "source": [
    "# Define the split time\n",
    "split_time = int(0.8*len(series))\n",
    "\n",
    "# Get the train set\n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "\n",
    "# Get the validation set\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_eI-dTP1ho-V"
   },
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    \"\"\"Generates dataset windows\n",
    "\n",
    "    Args:\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to include in the feature\n",
    "      batch_size (int) - the batch size\n",
    "      shuffle_buffer(int) - buffer size to use for the shuffle method\n",
    "\n",
    "    Returns:\n",
    "      dataset (TF Dataset) - TF Dataset containing time windows\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a TF Dataset from the series values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    # Window the data but only take those with the specified size\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Flatten the windows by putting its elements in a single batch\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "    # Create tuples with features and labels\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "    # Shuffle the windows\n",
    "    dataset = dataset.shuffle(shuffle_buffer)\n",
    "\n",
    "    # Create batches of windows\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PGJCMMYahusU"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "window_size = 30\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000\n",
    "\n",
    "# Generate the dataset windows\n",
    "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1727056788338,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "yTOq4iK7hwDB",
    "outputId": "6c5855fb-9008-4e16-dee9-74c8e110ed64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,251\n",
      "Trainable params: 1,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, input_shape=[window_size], activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76966,
     "status": "ok",
     "timestamp": 1727056868679,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "oZrVFCCRh21E",
    "outputId": "28ce7dc8-08c5-441f-ef68-3820dc903e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1232\\746229365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Thời gian huấn luyện'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1574\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m   1577\u001b[0m                         \u001b[1;34m\"Unexpected result of `train_function` \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m                         \u001b[1;34m\"(Empty logs). Please use \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "# Set the learning rate scheduler\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "# Set the training parameters\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])\n",
    "tg=time.time() - start_time\n",
    "print('Thời gian huấn luyện', tg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1727056880310,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "Z76WBHMdh93S",
    "outputId": "27297d9b-ef6d-4827-d764-dd78671ac9fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-08, 0.001, 0.0, 100.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAIMCAYAAAAHNWbDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAi8ElEQVR4nO3df3DXhX348dcHiEhs1BJqfkxB9MKqYv2BjkrVwClxtkp73q5uuGpvthcv2i5jjrqxdcGr4aSOspNWoX9Yth1Xvdtse7tuR+6GQZfuRCZdRzu1K4K2iZmYATFUInz2hyPfb4ZVAq+8Y/DxuOPavPP+fN6vz/ki3tP3hw+lcrlcDgAAAFJMGOsBAAAATiQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIJLIAAAASiSwAAIBEIgsAACDRiCNr8+bNceONN0Z9fX2USqX4zne+M+z75XI52traor6+PqZMmRLz58+P7du3DzvnjTfeiC984Qsxbdq0OOWUU2LRokXx8ssvH9cLAQAAeC8YcWS9/vrrcdFFF8WaNWve9vsrV66MVatWxZo1a2LLli1RW1sbCxcujH379g2d09raGo8//nh8+9vfjqeeeir6+/vjhhtuiIMHDx77KwEAAHgPKJXL5fIxP7hUiscffzw+9alPRcRbd7Hq6+ujtbU1vvSlL0XEW3etampq4v7774/m5ubYs2dPfOhDH4q//uu/jptvvjkiIn7xi1/EWWedFd///vfjuuuuO/5XBQAAMEYmZT7Zjh07oqenJ5qamoaOTZ48ORobG6Orqyuam5tj69atMTg4OOyc+vr6mD17dnR1db1tZHV3d0d3d/eIZjl06FBMmDAhzj333CiVSsf+ogAAgHGtXC7Hvn37or6+PiZMGP2PpUiNrJ6enoiIqKmpGXa8pqYmdu7cOXTOSSedFB/84AePOOfw4/+vtWvXxvLlyzNHBQAA3mdeeumlOPPMM0f9OqmRddj/vXNULpff9W7SO53T3NwcixYtGtEM+/bti/nz58fzzz8fU6dOHdFjYSQGBwdj06ZNsWDBgqioqBjrcTiB2TWKYtcoil2jKK+99lrMmjUrqqqqCrleamTV1tZGxFt3q+rq6oaO9/b2Dt3dqq2tjQMHDkRfX9+wu1m9vb0xb968t33eurq6Yc93NPbu3RsREVOnTo3q6uoRPRZGYnBwMCorK6O6utq/IBhVdo2i2DWKYtcoWlF/jCj1DYkzZ86M2tra6OjoGDp24MCB6OzsHAqoOXPmREVFxbBzuru749///d9/ZWQBAACMFyO+k9Xf3x8//elPh77esWNHbNu2LaZOnRrTp0+P1tbWaG9vj4aGhmhoaIj29vaorKyMxYsXR0TEaaedFrfffnv84R/+YVRXV8fUqVPj7rvvjgsvvDCuvfbavFcGAAAwBkYcWc8880wsWLBg6OslS5ZERMRtt90W3/rWt2Lp0qWxf//+aGlpib6+vpg7d25s3Lhx2Psfv/a1r8WkSZPi05/+dOzfvz+uueaa+Na3vhUTJ05MeEkAAABjZ8SRNX/+/Hinv1qrVCpFW1tbtLW1/cpzTj755HjwwQfjwQcfHOnlAQAA3tNG/0PiAQAA3kdEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJ0iPrzTffjD/90z+NmTNnxpQpU+Kcc86Je++9Nw4dOjR0Trlcjra2tqivr48pU6bE/PnzY/v27dmjAAAAFC49su6///54+OGHY82aNfGTn/wkVq5cGV/96lfjwQcfHDpn5cqVsWrVqlizZk1s2bIlamtrY+HChbFv377scQAAAAqVHlk/+MEP4pOf/GR84hOfiLPPPjt+67d+K5qamuKZZ56JiLfuYq1evTqWLVsWN910U8yePTvWr18fAwMDsWHDhuxxAAAACjUp+wmvvPLKePjhh+P555+PWbNmxQ9/+MN46qmnYvXq1RERsWPHjujp6Ymmpqahx0yePDkaGxujq6srmpubj3jO7u7u6O7uHtEc/f39ERExODgYg4ODx/6C4F0c3i97xmizaxTFrlEUu0ZRit6x9Mj60pe+FHv27IkPf/jDMXHixDh48GDcd9998Tu/8zsREdHT0xMRETU1NcMeV1NTEzt37nzb51y7dm0sX778mObZtGlTVFZWHtNjYSQ6OjrGegTeJ+waRbFrFMWuMdoGBgYKvV56ZD366KPxN3/zN7Fhw4a44IILYtu2bdHa2hr19fVx2223DZ1XKpWGPa5cLh9x7LDm5uZYtGjRiObo7++PxsbGWLBgQVRXV4/8hcBRGhwcjI6Ojli4cGFUVFSM9TicwOwaRbFrFMWuUZTdu3cXer30yPqjP/qjuOeee+K3f/u3IyLiwgsvjJ07d8aKFSvitttui9ra2oh4645WXV3d0ON6e3uPuLt1WF1d3bBzj8bevXsjIqKiosJvWgph1yiKXaModo2i2DVGW9H7lf7BFwMDAzFhwvCnnThx4tBHuM+cOTNqa2uH3RY+cOBAdHZ2xrx587LHAQAAKFT6nawbb7wx7rvvvpg+fXpccMEF8eyzz8aqVavi937v9yLirbcJtra2Rnt7ezQ0NERDQ0O0t7dHZWVlLF68OHscAACAQqVH1oMPPhh/9md/Fi0tLdHb2xv19fXR3NwcX/7yl4fOWbp0aezfvz9aWlqir68v5s6dGxs3boyqqqrscQAAAAqVHllVVVWxevXqoY9sfzulUina2tqira0t+/IAAABjKv3PZAEAALyfiSwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIJLIAAAASiSwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIJLIAAAASiSwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIJLIAAAASiSwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIJLIAAAASiSwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIJLIAAAASiSwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIJLIAAAASiSwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARKMSWT//+c/jd3/3d6O6ujoqKyvj4osvjq1btw59v1wuR1tbW9TX18eUKVNi/vz5sX379tEYBQAAoFDpkdXX1xcf+9jHoqKiIv7hH/4hfvzjH8df/MVfxOmnnz50zsqVK2PVqlWxZs2a2LJlS9TW1sbChQtj37592eMAAAAUalL2E95///1x1llnxSOPPDJ07Oyzzx76/+VyOVavXh3Lli2Lm266KSIi1q9fHzU1NbFhw4Zobm4+4jm7u7uju7t7RHP09/dHRMTg4GAMDg4ewyuBo3N4v+wZo82uURS7RlHsGkUpesdK5XK5nPmE559/flx33XXx8ssvR2dnZ/zar/1atLS0xOc///mIiPjZz34W5557bvzrv/5rXHLJJUOP++QnPxmnn356rF+//ojnbGtri+XLlx/TPBs2bIjKyspjezEAAMC4NzAwEIsXL449e/bEqaeeOurXS7+T9bOf/SweeuihWLJkSfzJn/xJPP300/HFL34xJk+eHLfeemv09PRERERNTc2wx9XU1MTOnTvf9jmbm5tj0aJFI5qjv78/GhsbY8GCBVFdXX1sLwaOwuDgYHR0dMTChQujoqJirMfhBGbXKIpdoyh2jaLs3r270OulR9ahQ4fisssui/b29oiIuOSSS2L79u3x0EMPxa233jp0XqlUGva4crl8xLHD6urqoq6ubkRz7N27NyIiKioq/KalEHaNotg1imLXKIpdY7QVvV/pH3xRV1cX559//rBj5513XuzatSsiImprayMihu5oHdbb23vE3S0AAIDxJj2yPvaxj8Vzzz037Njzzz8fM2bMiIiImTNnRm1tbXR0dAx9/8CBA9HZ2Rnz5s3LHgcAAKBQ6W8X/IM/+IOYN29etLe3x6c//el4+umnY926dbFu3bqIeOttgq2trdHe3h4NDQ3R0NAQ7e3tUVlZGYsXL84eBwAAoFDpkXX55ZfH448/Hn/8x38c9957b8ycOTNWr14dt9xyy9A5S5cujf3790dLS0v09fXF3LlzY+PGjVFVVZU9DgAAQKHSIysi4oYbbogbbrjhV36/VCpFW1tbtLW1jcblAQAAxkz6n8kCAAB4PxNZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQa9chasWJFlEqlaG1tHTpWLpejra0t6uvrY8qUKTF//vzYvn37aI8CAAAw6kY1srZs2RLr1q2Lj3zkI8OOr1y5MlatWhVr1qyJLVu2RG1tbSxcuDD27ds3muMAAACMulGLrP7+/rjlllvim9/8Znzwgx8cOl4ul2P16tWxbNmyuOmmm2L27Nmxfv36GBgYiA0bNozWOAAAAIWYNFpPfOedd8YnPvGJuPbaa+MrX/nK0PEdO3ZET09PNDU1DR2bPHlyNDY2RldXVzQ3Nx/xXN3d3dHd3T2i6/f390dExODgYAwODh7jq4B3d3i/7Bmjza5RFLtGUewaRSl6x0Ylsr797W/H1q1b45lnnjniez09PRERUVNTM+x4TU1N7Ny5822fb+3atbF8+fJjmmXTpk1RWVl5TI+Fkejo6BjrEXifsGsUxa5RFLvGaBsYGCj0eumR9dJLL8Xv//7vx8aNG+Pkk0/+leeVSqVhX5fL5SOOHdbc3ByLFi0a0Rz9/f3R2NgYCxYsiOrq6hE9FkZicHAwOjo6YuHChVFRUTHW43ACs2sUxa5RFLtGUXbv3l3o9dIja+vWrdHb2xtz5swZOnbw4MHYvHlzrFmzJp577rmIeOuOVl1d3dA5vb29R9zdOqyurm7YuUdj7969ERFRUVHhNy2FsGsUxa5RFLtGUewao63o/Ur/4ItrrrkmfvSjH8W2bduGfl122WVxyy23xLZt2+Kcc86J2traYbeFDxw4EJ2dnTFv3rzscQAAAAqVfierqqoqZs+ePezYKaecEtXV1UPHW1tbo729PRoaGqKhoSHa29ujsrIyFi9enD0OAABAoUbt0wXfydKlS2P//v3R0tISfX19MXfu3Ni4cWNUVVWNxTgAAABpComsJ554YtjXpVIp2traoq2trYjLAwAAFGbU/jJiAACA9yORBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJAoPbJWrFgRl19+eVRVVcUZZ5wRn/rUp+K5554bdk65XI62traor6+PKVOmxPz582P79u3ZowAAABQuPbI6OzvjzjvvjH/5l3+Jjo6OePPNN6OpqSlef/31oXNWrlwZq1atijVr1sSWLVuitrY2Fi5cGPv27cseBwAAoFCTsp/wH//xH4d9/cgjj8QZZ5wRW7dujauvvjrK5XKsXr06li1bFjfddFNERKxfvz5qampiw4YN0dzcfMRzdnd3R3d394jm6O/vj4iIwcHBGBwcPMZXA+/u8H7ZM0abXaModo2i2DWKUvSOpUfW/7Vnz56IiJg6dWpEROzYsSN6enqiqalp6JzJkydHY2NjdHV1vW1krV27NpYvX35M19+0aVNUVlYe02NhJDo6OsZ6BN4n7BpFsWsUxa4x2gYGBgq93qhGVrlcjiVLlsSVV14Zs2fPjoiInp6eiIioqakZdm5NTU3s3LnzbZ+nubk5Fi1aNKJr9/f3R2NjYyxYsCCqq6uPYXo4OoODg9HR0RELFy6MioqKsR6HE5hdoyh2jaLYNYqye/fuQq83qpF11113xb/927/FU089dcT3SqXSsK/L5fIRxw6rq6uLurq6EV177969ERFRUVHhNy2FsGsUxa5RFLtGUewao63o/Rq1j3D/whe+EN/73vdi06ZNceaZZw4dr62tjYj/d0frsN7e3iPubgEAAIw36ZFVLpfjrrvuir/7u7+Lf/qnf4qZM2cO+/7MmTOjtrZ22HtvDxw4EJ2dnTFv3rzscQAAAAqV/nbBO++8MzZs2BDf/e53o6qqauiO1WmnnRZTpkyJUqkUra2t0d7eHg0NDdHQ0BDt7e1RWVkZixcvzh4HAACgUOmR9dBDD0VExPz584cdf+SRR+Kzn/1sREQsXbo09u/fHy0tLdHX1xdz586NjRs3RlVVVfY4AAAAhUqPrHK5/K7nlEqlaGtri7a2tuzLAwAAjKlR++ALAACA9yORBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAEAikQUAAJBIZAEAACQSWQAAAIlEFgAAQCKRBQAAkEhkAQAAJBJZAAAAiUQWAABAIpEFAACQSGQBAAAkElkAAACJRBYAAECiMY2sb3zjGzFz5sw4+eSTY86cOfHkk0+O5TgAAADHbcwi69FHH43W1tZYtmxZPPvss3HVVVfF9ddfH7t27RqrkQAAAI7bmEXWqlWr4vbbb4/Pfe5zcd5558Xq1avjrLPOioceemisRgIAADhuk8biogcOHIitW7fGPffcM+x4U1NTdHV1HXF+d3d3dHd3j+ga+/bti4iI11577dgHhaMwODgYAwMDsXv37qioqBjrcTiB2TWKYtcoil2jKIeboFwuF3K9MYmsV199NQ4ePBg1NTXDjtfU1ERPT88R569duzaWL19+TNeaNWvWMT0OAAA4sfznf/5nXHrppaN+nTGJrMNKpdKwr8vl8hHHIiKam5tj0aJFI3ru7du3x6233hpPPPFEXHLJJcc1Z9G2bdsWjY2N0dnZGRdffPG4utbxPN9IH3u05x/Nee92zjt9v8h/Xtnsml0ril2za0Wxa3atKHZtfO3as88+G/Pnz49Dhw6968wZxiSypk2bFhMnTjzirlVvb+8Rd7ciIurq6qKuru6YrlVVVRWnnnrqMT12rHzgAx8Y+t/Rnj37WsfzfCN97NGefzTnvds57/T9Iv95ZbNrdq0ods2uFcWu2bWi2LXxtWtVVVURETFhQjEfSTEmH3xx0kknxZw5c6Kjo2PY8Y6Ojpg3b95YjAQAAJBizN4uuGTJkvjMZz4Tl112WVxxxRWxbt262LVrV9xxxx1jNRIAAMBxG7PIuvnmm2P37t1x7733Rnd3d8yePTu+//3vx4wZM8ZqJAAAgOM2ph980dLSEi0tLWM5AgAAQKox+8uIAQAATkQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABIdMJGVl1dXfz5n/951NXVjfUoI1bk7NnXOp7nG+ljj/b8oznv3c55p+/btbG5ll0bX+yaXSuKXbNrRbFrdu2dlMrlcrmQKwEAALwPnLB3sgAAAMaCyAIAAEgksgAAABKJLAAAgEQiCwAAIJHI+l9f+9rX4oILLojzzz8/vvjFL4YPXWQ0PPfcc3HxxRcP/ZoyZUp85zvfGeuxOEHt2LEjFixYEOeff35ceOGF8frrr4/1SJygJk2aNPRz7XOf+9xYj8MJbmBgIGbMmBF33333WI/CCWrfvn1x+eWXx8UXXxwXXnhhfPOb3xzxc/gI94j4r//6r/joRz8a27dvj4qKirj66qvjgQceiCuuuGKsR+ME1t/fH2effXbs3LkzTjnllLEehxNQY2NjfOUrX4mrrroqXnvttTj11FNj0qRJYz0WJ6Bp06bFq6++OtZj8D6xbNmyeOGFF2L69OnxwAMPjPU4nIAOHjwYb7zxRlRWVsbAwEDMnj07tmzZEtXV1Uf9HO5k/a8333wzfvnLX8bg4GAMDg7GGWecMdYjcYL73ve+F9dcc43AYlQc/o9GV111VURETJ06VWAB494LL7wQ//Ef/xEf//jHx3oUTmATJ06MysrKiIj45S9/GQcPHhzxu9zGRWRt3rw5brzxxqivr49SqfS2b6/6xje+ETNnzoyTTz455syZE08++eRRP/+HPvShuPvuu2P69OlRX18f1157bZx77rmJr4DxYrR37f/32GOPxc0333ycEzNejfauvfDCC/GBD3wgFi1aFJdeemm0t7cnTs94UsTPtb1798acOXPiyiuvjM7OzqTJGW+K2LW77747VqxYkTQx41URu/bf//3fcdFFF8WZZ54ZS5cujWnTpo3o8eMisl5//fW46KKLYs2aNW/7/UcffTRaW1tj2bJl8eyzz8ZVV10V119/fezatWvonDlz5sTs2bOP+PWLX/wi+vr64u///u/jxRdfjJ///OfR1dUVmzdvLurl8R4y2rt22N69e+Of//mf/Ze497HR3rXBwcF48skn4+tf/3r84Ac/iI6Ojujo6Cjq5fEeUsTPtRdffDG2bt0aDz/8cNx6662xd+/eQl4b7y2jvWvf/e53Y9asWTFr1qyiXhLvUUX8XDv99NPjhz/8YezYsSM2bNgQr7zyysiGLI8zEVF+/PHHhx37jd/4jfIdd9wx7NiHP/zh8j333HNUz/nYY4+VW1pahr5euXJl+f777z/uWRnfRmPXDvurv/qr8i233HK8I3KCGI1d6+rqKl933XVDX69cubK8cuXK456V8W00f64d9pu/+ZvlLVu2HOuInCBGY9fuueee8plnnlmeMWNGubq6unzqqaeWly9fnjUy41QRP9fuuOOO8mOPPTaix4yLO1nv5MCBA7F169ZoamoadrypqSm6urqO6jnOOuus6OrqGnrP5RNPPBG//uu/PhrjMo5l7Nph3irIO8nYtcsvvzxeeeWV6Ovri0OHDsXmzZvjvPPOG41xGccydq2vry/eeOONiIh4+eWX48c//nGcc8456bMyvmXs2ooVK+Kll16KF198MR544IH4/Oc/H1/+8pdHY1zGsYxde+WVV4buyO/duzc2b9484jYY938K+tVXX42DBw9GTU3NsOM1NTXR09NzVM/x0Y9+ND7+8Y/HJZdcEhMmTIhrrrkmFi1aNBrjMo5l7FpExJ49e+Lpp5+Ov/3bv80ekRNExq5NmjQp2tvb4+qrr45yuRxNTU1xww03jMa4jGMZu/aTn/wkmpubY8KECVEqleIv//IvY+rUqaMxLuNY1r9D4d1k7NrLL78ct99+e5TL5SiXy3HXXXfFRz7ykRHNMe4j67BSqTTs63K5fMSxd3LffffFfffdlz0WJ6Dj3bXTTjtt5O/r5X3peHft+uuvj+uvvz57LE5Ax7Nr8+bNix/96EejMRYnoOP9uXbYZz/72aSJOFEdz67NmTMntm3bdlzXH/dvF5w2bVpMnDjxiDLt7e09omDheNg1imLXKIpdoyh2jaK8V3Zt3EfWSSedFHPmzDniU7M6Ojpi3rx5YzQVJyK7RlHsGkWxaxTFrlGU98qujYu3C/b398dPf/rToa937NgR27Zti6lTp8b06dNjyZIl8ZnPfCYuu+yyuOKKK2LdunWxa9euuOOOO8ZwasYju0ZR7BpFsWsUxa5RlHGxa8f0OYYF27RpUzkijvh12223DZ3z9a9/vTxjxozySSedVL700kvLnZ2dYzcw45Zdoyh2jaLYNYpi1yjKeNi1UrlcLhcRcwAAAO8H4/7PZAEAALyXiCwAAIBEIgsAACCRyAIAAEgksgAAABKJLAAAgEQiCwAAIJHIAgAASCSyAAAAEoksAACARCILAAAgkcgCAABI9D+np0ZkPvmRKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the learning rate array\n",
    "lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot the loss in log scale\n",
    "plt.semilogx(lrs, history.history[\"loss\"])\n",
    "\n",
    "# Increase the tickmarks size\n",
    "plt.tick_params('both', length=10, width=1, which='both')\n",
    "\n",
    "# Set the plot boundaries\n",
    "plt.axis([1e-8, 1e-3, 0, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GCz8PBSsiPJt"
   },
   "outputs": [],
   "source": [
    "# Reset states generated by Keras\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build the Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, input_shape=[window_size], activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(20, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72714,
     "status": "ok",
     "timestamp": 1727062809416,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "786LsJ5piSI_",
    "outputId": "63de70f3-0c60-42df-f9d8-0d2eb0e7e4a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 22533.4785 - mse: 508456160.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 134519.7812 - mse: 18199818240.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 50326.8945 - mse: 2535863552.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 22799.0352 - mse: 520040672.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 22799.0352 - mse: 520040672.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 22799.0352 - mse: 520040672.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22799.0352 - mse: 520040672.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 22799.0352 - mse: 520040672.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 22799.0332 - mse: 520040672.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 22799.0312 - mse: 520040544.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 22799.0332 - mse: 520040544.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 22799.0332 - mse: 520040544.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22799.0332 - mse: 520040544.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 22799.0312 - mse: 520040480.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 22799.0312 - mse: 520040480.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 22799.0293 - mse: 520040384.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 22799.0273 - mse: 520040384.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 22799.0273 - mse: 520040288.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 22799.0273 - mse: 520040224.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 22799.0254 - mse: 520040224.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 22799.0215 - mse: 520040128.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22799.0215 - mse: 520040032.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 22799.0176 - mse: 520039936.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 22799.0176 - mse: 520039872.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 22799.0156 - mse: 520039776.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 22799.0156 - mse: 520039744.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 22799.0137 - mse: 520039680.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 22799.0137 - mse: 520039616.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 22799.0098 - mse: 520039488.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22799.0039 - mse: 520039328.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 22799.0020 - mse: 520039232.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 22799.0020 - mse: 520039136.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 22799.0000 - mse: 520039072.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 22799.0000 - mse: 520038976.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 22798.9961 - mse: 520038880.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 22798.9961 - mse: 520038816.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 22798.9902 - mse: 520038624.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 22798.9863 - mse: 520038496.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 22798.9863 - mse: 520038432.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 22798.9824 - mse: 520038368.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 22798.9824 - mse: 520038240.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22798.9785 - mse: 520038080.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 22798.9785 - mse: 520037952.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 22798.9727 - mse: 520037888.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22798.9727 - mse: 520037824.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22798.9688 - mse: 520037600.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.9668 - mse: 520037568.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22798.9648 - mse: 520037440.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22798.9648 - mse: 520037376.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22798.9590 - mse: 520037184.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 22798.9551 - mse: 520037088.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 22798.9551 - mse: 520037024.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22798.9512 - mse: 520036864.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22798.9492 - mse: 520036704.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22798.9473 - mse: 520036640.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22798.9473 - mse: 520036576.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22798.9395 - mse: 520036352.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22798.9395 - mse: 520036288.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22798.9375 - mse: 520036192.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.9336 - mse: 520036032.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22798.9336 - mse: 520035936.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 22798.9277 - mse: 520035840.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.9238 - mse: 520035648.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22798.9238 - mse: 520035584.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22798.9199 - mse: 520035488.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22798.9199 - mse: 520035392.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22798.9160 - mse: 520035264.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22798.9160 - mse: 520035136.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 22798.9102 - mse: 520035040.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22798.9082 - mse: 520034880.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.9062 - mse: 520034784.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.9043 - mse: 520034720.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.9023 - mse: 520034528.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8965 - mse: 520034464.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22798.8965 - mse: 520034336.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.8926 - mse: 520034144.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 22798.8887 - mse: 520034080.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8887 - mse: 520033984.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22798.8848 - mse: 520033792.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8809 - mse: 520033728.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8809 - mse: 520033632.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22798.8789 - mse: 520033504.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22798.8750 - mse: 520033344.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 22798.8730 - mse: 520033280.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22798.8711 - mse: 520033216.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 22798.8652 - mse: 520032992.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.8652 - mse: 520032928.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8613 - mse: 520032832.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8574 - mse: 520032608.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8574 - mse: 520032544.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 22798.8555 - mse: 520032480.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 22798.8535 - mse: 520032288.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.8496 - mse: 520032224.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 22798.8477 - mse: 520032096.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 22798.8438 - mse: 520031968.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22798.8438 - mse: 520031808.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 22798.8398 - mse: 520031744.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 22798.8398 - mse: 520031680.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 22798.8340 - mse: 520031488.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 22798.8301 - mse: 520031424.0000\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "# Set the training parameters\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mse\"])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_set,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "751bkoX1im-E"
   },
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    \"\"\"Uses an input model to generate predictions on data windows\n",
    "\n",
    "    Args:\n",
    "      model (TF Keras Model) - model that accepts data windows\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to include in the window\n",
    "      batch_size (int) - the batch size\n",
    "\n",
    "    Returns:\n",
    "      forecast (numpy array) - array containing predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a TF Dataset from the series values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    # Window the data but only take those with the specified size\n",
    "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Flatten the windows by putting its elements in a single batch\n",
    "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
    "\n",
    "    # Create batches of windows\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    # Get predictions on the entire dataset\n",
    "    forecast = model.predict(dataset)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1332,
     "status": "ok",
     "timestamp": 1727062708649,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "xeN_ZmBVioj4",
    "outputId": "a0a48c4b-f01d-420e-e149-6887f36202f0"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1232\\18081663.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Use helper function to generate predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mforecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_forecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforecast_series\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Drop single dimensional axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1232\\2961552756.py\u001b[0m in \u001b[0;36mmodel_forecast\u001b[1;34m(model, series, window_size, batch_size)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Get predictions on the entire dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mforecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2276\u001b[0m                         )\n\u001b[0;32m   2277\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_outputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2278\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   2279\u001b[0m                     \u001b[1;34m\"Unexpected result of `predict_function` \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2280\u001b[0m                     \u001b[1;34m\"(Empty batch_outputs). Please use \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "# Reduce the original series\n",
    "forecast_series = series[split_time-window_size:-1]\n",
    "\n",
    "# Use helper function to generate predictions\n",
    "forecast = model_forecast(model, forecast_series, window_size, batch_size)\n",
    "\n",
    "# Drop single dimensional axis\n",
    "results = forecast.squeeze()\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x_valid, results))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1727062718479,
     "user": {
      "displayName": "Đặng Thị Kiêm Hồng",
      "userId": "05445281411830122382"
     },
     "user_tz": -420
    },
    "id": "9kJpbJJpq6Dq",
    "outputId": "3e4bff22-5427-439f-ab55-4db816939fe7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(actual, predicted):\n",
    "    return np.mean((actual - predicted) ** 2)\n",
    "\n",
    "# Tính MSE\n",
    "mse = mean_squared_error(x_valid, results)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Đọc dữ liệu CPI\n",
    "data = pd.read_csv('D:\\DeTaiNam2024\\SoLieu\\KinhTeViMo\\gdp.csv')  # Thay 'path_to_cpi_data.csv' bằng đường dẫn của bạn\n",
    "data = data['GDP_VN'].values  # Giả sử cột CPI chứa chỉ số cần dự báo\n",
    "data = data.reshape(-1, 1)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Tạo chuỗi thời gian\n",
    "sequence_length = 12  # Ví dụ dùng 12 tháng để dự báo tháng tiếp theo\n",
    "X, y = [], []\n",
    "for i in range(sequence_length, len(data_scaled)):\n",
    "    X.append(data_scaled[i-sequence_length:i, 0])\n",
    "    y.append(data_scaled[i, 0])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Chia tập huấn luyện và kiểm tra\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTMCell, RNN\n",
    "\n",
    "class sLSTMCell(LSTMCell):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(sLSTMCell, self).__init__(units, **kwargs)\n",
    "    \n",
    "    def call(self, inputs, states, training=None):\n",
    "        # Gọi hàm LSTM mặc định\n",
    "        h, [c, h] = super(sLSTMCell, self).call(inputs, states, training=training)\n",
    "        \n",
    "        # Tùy chỉnh cổng quên và cổng đầu vào\n",
    "        forget_gate = tf.math.exp(c)  # Sử dụng hàm mũ e cho cổng quên\n",
    "        input_gate = tf.math.exp(2 * c)  # Sử dụng hàm mũ cơ số 2 cho cổng đầu vào\n",
    "        \n",
    "        # Áp dụng các cổng vào trạng thái bộ nhớ\n",
    "        new_c = forget_gate * c + input_gate * h\n",
    "        \n",
    "        # Trả về trạng thái cập nhật và output\n",
    "        return h, [new_c, h]\n",
    "\n",
    "# Tạo lớp RNN với sLSTMCell\n",
    "def build_sLSTM_model(input_shape, units=50):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    sLSTM_layer = RNN(sLSTMCell(units))(inputs)\n",
    "    output = tf.keras.layers.Dense(1)(sLSTM_layer)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Xây dựng mô hình sLSTM\n",
    "model = build_sLSTM_model((X_train.shape[1], 1))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện mô hình\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "predicted_cpi = model.predict(X_test)\n",
    "\n",
    "# Chuyển đổi giá trị dự đoán về dạng CPI ban đầu\n",
    "predicted_cpi = scaler.inverse_transform(predicted_cpi)\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Tính toán các chỉ số đánh giá\n",
    "mse = mean_squared_error(y_test_actual, predicted_cpi)\n",
    "mae = mean_absolute_error(y_test_actual, predicted_cpi)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Vẽ biểu đồ dự đoán và giá trị thực tế\n",
    "plt.plot(y_test_actual, color='blue', label='Actual CPI')\n",
    "plt.plot(predicted_cpi, color='red', label='Predicted CPI')\n",
    "plt.title('CPI Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('CPI')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOy2QCqOk/AA+RkmIoGixk1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
